OpenAI 在当地时间周一 发布 了名为 GPT-4.1 的新模型系列，共包含：GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano。

公告称，这些模型的性能全面超越 GPT-4o 和 GPT-4o mini，在编码和指令跟踪方面均有显著提升。它们拥有一个包含 100 万个 token 的上下文窗口，这意味着它们可以一次性输入大约 75 万个单词，并且能够通过改进的长上下文理解更好地利用这些上下文，同时其知识截止日期已更新至 2024 年 6 月。

这些多模态模型可以通过 OpenAI 的 API 获取，但 ChatGPT 无法使用。

GPT-4.1 的到来正值 OpenAI 的竞争对手谷歌和 Anthropic 加紧构建复杂编程模型之际。谷歌最近发布的 Gemini 2.5 Pro 也拥有 100 万个 token 上下文窗口，在热门编码基准测试中名列前茅。Anthropic 的 Claude 3.7 Sonnet 和  DeepSeek 的升级版 V3 也同样名列前茅。

训练能够执行复杂软件工程任务的 AI 编码模型是包括 OpenAI 在内的许多科技巨头的目标。OpenAI 的宏伟目标是打造 “代理软件工程师”，正如其首席财务官 Sarah Friar 上个月在伦敦举行的一次科技峰会上所说。该公司声称，其未来的模型将能够端到端地编写整个应用程序，处理质量保证、错误测试和文档编写等方面的工作。

GPT-4.1 是朝着这个方向迈出的一步。

OpenAI 的一位发言人通过电子邮件告诉 TechCrunch：“我们根据直接反馈对 GPT-4.1 进行了优化，使其更适合实际使用，从而改进了开发者最关心的领域：前端编码、减少不必要的编辑、可靠地遵循格式、遵循响应结构和顺序、保持一致的工具使用等等。这些改进使开发者能够构建出在实际软件工程任务中表现更出色的代理。”

OpenAI 声称，完整的 GPT-4.1 模型在包括 SWE-bench 在内的编码基准测试中均优于其 GPT-4o 和 GPT-4o mini 模型。据称，GPT-4.1 mini 和 nano 效率更高、速度更快，但准确性有所降低。OpenAI 表示，GPT-4.1 nano 是其迄今为止速度最快、成本最低的模型。

GPT-4.1 每百万输入 token 成本为 2 美元，每百万输出 token 成本为 8 美元。GPT-4.1 mini 每百万输入 token 成本为 0.40 美元，每百万输出 token 成本为 1.60 美元；GPT-4.1 nano 每百万输入 token 成本为 0.10 美元，每百万输出 token 成本为 0.40 美元。

根据 OpenAI 的内部测试，GPT-4.1 可以一次性生成比 GPT-4o 更多的 token（32,768 对 16,384），在 SWE-bench Verified 上的得分在 52% 到 54.6% 之间。这些数字略低于谷歌和 Anthropic 在同一基准测试中分别报告的 Gemini 2.5 Pro（63.8%）和 Claude 3.7 Sonnet（62.3%）的得分。


在另一项评估中，OpenAI 使用 Video-MME 测试了 GPT-4.1，该模型旨在衡量模型 “理解” 视频内容的能力。OpenAI 声称，GPT-4.1 在 “长篇无字幕” 视频类别中达到了 72% 的最高准确率。

虽然 GPT-4.1 在基准测试中得分相当不错，并且 “知识截止” 时间也较新，使其能够更好地参考时事（截至 2024 年 6 月），但必须牢记，即使是当今一些最好的模型，在处理一些专家不会犯错的任务时也会遇到困难。例如，许多研究表明 ，代码生成模型通常无法修复安全漏洞和 bug，甚至会引入这些漏洞。

OpenAI 也承认，GPT-4.1 处理的输入 token 越多，可靠性就越低（即更容易出错）。在该公司自己的测试 OpenAI-MRCR 中，该模型的准确率从 8,000 个 token 时的 84% 左右下降到 100 万个 token 时的 50%。该公司表示，GPT-4.1 也比 GPT-4o 更 “直白”，有时需要更具体、更明确的提示。
